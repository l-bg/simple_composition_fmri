{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An fMRI study of composition in noun and verb phrases\n",
    "### Bonnasse-Gahot, Bemis, Perez-Guevara, Dehaene, Pallier\n",
    "Generate the events for the incremental model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import simpcomp as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressors are:\n",
    "# cs : consonant string\n",
    "# wn1 : first word in a noun sequence\n",
    "# wnp : word added to a noun phrase\n",
    "# wnl : word added to a noun list\n",
    "# wv1 : first word in a verb sequence\n",
    "# wvp : word added to a verb phrase\n",
    "# wvl : word added to a verb list\n",
    "# probe\n",
    "# resp_r : response key right\n",
    "# resp_l : response key left \n",
    "\n",
    "def create_model_events(full_events):\n",
    "    model_events = pd.DataFrame(columns=['onset', 'duration', 'trial_type']) \n",
    "\n",
    "    is_first_word = True\n",
    "    for idx, event in full_events.iterrows():    \n",
    "        if event.stim.isupper(): # probe        \n",
    "            model_events = model_events.append(pd.Series({'onset':event.onset,\n",
    "                                                          'duration':0.0,\n",
    "                                                          'trial_type':'probe'}),\n",
    "                                               ignore_index=True)\n",
    "        elif event.stim == '[response]':\n",
    "            if event.response_key == 'y':\n",
    "                trial_type = 'resp_r'\n",
    "            else:\n",
    "                trial_type = 'resp_l'\n",
    "            model_events = model_events.append(pd.Series({'onset':event.onset,\n",
    "                                                          'duration':0.0,\n",
    "                                                          'trial_type':trial_type}),\n",
    "                                               ignore_index=True)\n",
    "        # check whether it's a consonant string or a word\n",
    "        # cheap here -- simply look whether it contains at least one vowel\n",
    "        elif not np.any([letter_tmp in 'aeiouyàèùéâêîôûëïüÿ' for letter_tmp in event.stim]): # consonant string\n",
    "        #sum([letter_tmp in 'aeiouyàèùéâêîôûëïüÿ' for letter_tmp in event.stim])>0:\n",
    "            model_events = model_events.append(pd.Series({'onset':event.onset,\n",
    "                                                          'duration':event.duration,\n",
    "                                                          'trial_type':'cs'}),\n",
    "                                               ignore_index=True)\n",
    "            is_first_word = True # reinitialize is_first_word, as sequences always begin with a consonant string\n",
    "        elif is_first_word:\n",
    "            model_events = model_events.append(pd.Series({'onset':event.onset,\n",
    "                                                          'duration':event.duration,\n",
    "                                                          'trial_type':'w{}1'.format(event.trial_type[0])}),\n",
    "                                               ignore_index=True)\n",
    "            is_first_word = False\n",
    "        else:\n",
    "            model_events = model_events.append(pd.Series({'onset':event.onset,\n",
    "                                                          'duration':event.duration,\n",
    "                                                          'trial_type':'w{}{}'.format(event.trial_type[0],\n",
    "                                                                                      event.trial_structure[0])}),\n",
    "                                               ignore_index=True)\n",
    "    return model_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_id in sc.subject_list:\n",
    "    dir_tmp = op.join(sc.model_incremental_folder, 'events', sub_id)\n",
    "    sc.make_dir(dir_tmp)\n",
    "    for indrun in range(1,5):\n",
    "        filename_in = op.join(sc.events_folder, sub_id, 'func',\n",
    "                   '{}_task-maindesign_run-{:02d}_events.tsv'.format(sub_id, indrun))\n",
    "        full_events = pd.read_csv(filename_in, sep='\\t')\n",
    "        full_events.drop(full_events[full_events.stim=='+'].index, inplace=True)\n",
    "        model_events = create_model_events(full_events)\n",
    "        \n",
    "        filename_out = op.join(dir_tmp, \n",
    "                      '{}_model-incremental_run-{:02d}_events.tsv'.format(sub_id, indrun))\n",
    "        model_events.to_csv(filename_out, index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
